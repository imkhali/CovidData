{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta\n",
    "from urllib.error import HTTPError\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Links for daily files\n",
    "def get_list_of_links(start=pd.Timestamp(2020,1,22), end=pd.Timestamp.today()):\n",
    "    \"\"\"Return a list of valid links corresponding to data files between start and end dates\"\"\"\n",
    "    base_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "    if start <= end <= pd.Timestamp.today():\n",
    "        dates = pd.date_range(start, end, freq='D')\n",
    "    else:\n",
    "        print(\"Dates are not valid\")\n",
    "\n",
    "    return (base_url + day.strftime('%m-%d-%Y') + '.csv' for day in dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-to-1 map of a column stub and a new column name (stub is chosen to be in that column in all raw files)\n",
    "def fix_column_name(raw_col_name):\n",
    "    \"\"\"\n",
    "    return a unified name for each column in raw data from stub_column_mapper if one of stubs in stub_column_mapper is in the raw column name,\n",
    "    otherwise return the raw column name itself\n",
    "    \"\"\"\n",
    "    stub_column_mapper = {\n",
    "    'vinc': 'Province',\n",
    "    'untr': 'Country',\n",
    "    'ips': 'FIPS',\n",
    "    'pda': 'Last_Update',\n",
    "    'lat': 'Latitude',\n",
    "    'long': 'Longitude',\n",
    "    'firm': 'Confirmed',\n",
    "    'eath': 'Deaths',\n",
    "    'cov': 'Recovered',\n",
    "    'tive': 'Active',\n",
    "    'bin': 'Combined_Key'\n",
    "    }\n",
    "    for stub in stub_column_mapper:\n",
    "        if stub in raw_col_name.lower():\n",
    "            return stub_column_mapper[stub]\n",
    "    return raw_col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Data to One CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Main_Data = []\n",
    "for link in get_list_of_links():\n",
    "    filename = link.split('/')[-1]\n",
    "\t# check if a daily data file is already downloaded\n",
    "    if os.path.exists(f'Daily_files\\\\{filename}'):\n",
    "        df = pd.read_csv(f'Daily_files\\\\{filename}')\n",
    "    else:\t# download if not\n",
    "        try:\n",
    "            df = pd.read_csv(link)\n",
    "            columns = {oldCol: fix_column_name(oldCol) for oldCol in df.columns}\n",
    "            df.rename(columns=columns, inplace=True)\n",
    "            df = df[list(columns.values())]\n",
    "            df.to_csv(f'Daily_files//{filename}', index=False)\n",
    "            print(f'Successfully saved: {filename}')\n",
    "        except HTTPError:\n",
    "            print(\"No Covid data file for {}\".format(filename.split('.')[0]))\n",
    "    # one big list of dataframes       \n",
    "    Main_Data.append(df)\n",
    "    \n",
    "# one dataframe for all days\n",
    "covid = pd.concat(Main_Data, ignore_index=True, sort=False)\n",
    "# one csv file for all days\n",
    "covid.to_csv('alldays_data.csv', index=False)\n",
    "print('Successfully updated alldays_data.csv')\n",
    "del Main_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Country</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>Case_Fatality_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province         Country      Last_Update  Confirmed  Deaths  Recovered  \\\n",
       "0      Anhui  Mainland China  1/22/2020 17:00        1.0     NaN        NaN   \n",
       "1    Beijing  Mainland China  1/22/2020 17:00       14.0     NaN        NaN   \n",
       "2  Chongqing  Mainland China  1/22/2020 17:00        6.0     NaN        NaN   \n",
       "3     Fujian  Mainland China  1/22/2020 17:00        1.0     NaN        NaN   \n",
       "4      Gansu  Mainland China  1/22/2020 17:00        NaN     NaN        NaN   \n",
       "\n",
       "   Latitude  Longitude  FIPS  Active Combined_Key Admin2  Lat  Long_  \\\n",
       "0       NaN        NaN   NaN     NaN          NaN    NaN  NaN    NaN   \n",
       "1       NaN        NaN   NaN     NaN          NaN    NaN  NaN    NaN   \n",
       "2       NaN        NaN   NaN     NaN          NaN    NaN  NaN    NaN   \n",
       "3       NaN        NaN   NaN     NaN          NaN    NaN  NaN    NaN   \n",
       "4       NaN        NaN   NaN     NaN          NaN    NaN  NaN    NaN   \n",
       "\n",
       "   Incident_Rate Case_Fatality_Ratio  \n",
       "0            NaN                 NaN  \n",
       "1            NaN                 NaN  \n",
       "2            NaN                 NaN  \n",
       "3            NaN                 NaN  \n",
       "4            NaN                 NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for USA (scrapping Worldometer table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "link = \"https://www.worldometers.info/coronavirus/country/us/\"\n",
    "\n",
    "response = requests.get(link)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# table header\n",
    "thead = soup.find_all('thead')[0] # many tables might exist\n",
    "colnames = [tag.get_text() for tag in thead.find_all(['th'])[:-2]] # last two cells among header irrelevant\n",
    "\n",
    "# table rows\n",
    "tbody = soup.find_all('tbody')\n",
    "\n",
    "rows_data = {} \n",
    "tr_tags = tbody[0].find_all(['tr'])   # tbody[0] as other tables exist\n",
    "for tr in tr_tags:                  # loop over table rows\n",
    "    tr_data = [td.get_text() for td in tr.find_all('td')[:-2]] # loop over row divisions (i.e cells) # last two cells irrelevant\n",
    "    rows_data[tr_data[0].strip()] = tr_data[1:]                # mapping row index (1st cell) to row data (other cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successsfully saved: usa_worldometer.csv\n"
     ]
    }
   ],
   "source": [
    "# a dataframe of the scrapped table    \n",
    "df = pd.DataFrame(rows_data).T\n",
    "df.columns = [col.replace('\\n', ' ') for col in colnames[1:]] # one used as index name\n",
    "df.index.name = colnames[0]\n",
    "\n",
    "df = df.applymap(lambda x: x\\\n",
    "                 .strip()\\\n",
    "                 .replace(',', '')\\\n",
    "                 .replace('+', ''))\n",
    "# save to csv\n",
    "df.to_csv('usa_worldometer.csv')\n",
    "print('Successsfully saved: usa_worldometer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worldometer main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "link = \"https://www.worldometers.info/coronavirus/\"\n",
    "\n",
    "response = requests.get(link)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# table header\n",
    "thead = soup.find_all('thead')[0] # many tables might exist\n",
    "colnames = [tag.get_text() for tag in thead.find_all(['th'])[:-2]] # last two cells among header irrelevant\n",
    "\n",
    "# table rows\n",
    "tbody = soup.find_all('tbody')\n",
    "\n",
    "rows_data = {} \n",
    "tr_tags = tbody[0].find_all(['tr'])   # tbody[0] as other tables exist\n",
    "for tr in tr_tags:                  # loop over table rows\n",
    "    tr_data = [td.get_text() for td in tr.find_all('td')[:-2]] # loop over row divisions (i.e cells) # last two cells irrelevant\n",
    "    rows_data[tr_data[0].strip()] = tr_data[1:]                # mapping row index (1st cell) to row data (other cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successsfully saved: world_worldometer.csv\n"
     ]
    }
   ],
   "source": [
    "# a dataframe of the scrapped table    \n",
    "df = pd.DataFrame(rows_data).T\n",
    "df.columns = [col.replace('\\n', ' ').replace(',', ' ') for col in colnames[1:]] # one used as index name\n",
    "df.index.name = colnames[0]\n",
    "\n",
    "# replacing weird characters in the data\n",
    "df = df.applymap(lambda x: x\\\n",
    "                 .strip()\\\n",
    "                 .replace(',', '')\\\n",
    "                 .replace('+', ''))\n",
    "# save to csv\n",
    "df.to_csv('world_worldometer.csv', index=False)\n",
    "print('Successsfully saved: world_worldometer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Other</th>\n",
       "      <th>TotalCases</th>\n",
       "      <th>NewCases</th>\n",
       "      <th>TotalDeaths</th>\n",
       "      <th>NewDeaths</th>\n",
       "      <th>TotalRecovered</th>\n",
       "      <th>NewRecovered</th>\n",
       "      <th>ActiveCases</th>\n",
       "      <th>Serious Critical</th>\n",
       "      <th>Tot Cases/1M pop</th>\n",
       "      <th>Deaths/1M pop</th>\n",
       "      <th>TotalTests</th>\n",
       "      <th>Tests/ 1M pop</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>1 Caseevery X ppl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>World</td>\n",
       "      <td>118630045</td>\n",
       "      <td>8800</td>\n",
       "      <td>2631996</td>\n",
       "      <td>729</td>\n",
       "      <td>94238652</td>\n",
       "      <td>6802</td>\n",
       "      <td>21759397</td>\n",
       "      <td>89790</td>\n",
       "      <td>15219</td>\n",
       "      <td>337.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>29862124</td>\n",
       "      <td></td>\n",
       "      <td>542191</td>\n",
       "      <td></td>\n",
       "      <td>20640270</td>\n",
       "      <td></td>\n",
       "      <td>8679663</td>\n",
       "      <td>12607</td>\n",
       "      <td>89854</td>\n",
       "      <td>1631</td>\n",
       "      <td>373104726</td>\n",
       "      <td>1122655</td>\n",
       "      <td>332341490</td>\n",
       "      <td>North America</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>11284311</td>\n",
       "      <td></td>\n",
       "      <td>158213</td>\n",
       "      <td></td>\n",
       "      <td>10935803</td>\n",
       "      <td></td>\n",
       "      <td>190295</td>\n",
       "      <td>8944</td>\n",
       "      <td>8122</td>\n",
       "      <td>114</td>\n",
       "      <td>223479877</td>\n",
       "      <td>160853</td>\n",
       "      <td>1389345702</td>\n",
       "      <td>Asia</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>11205972</td>\n",
       "      <td></td>\n",
       "      <td>270917</td>\n",
       "      <td></td>\n",
       "      <td>9913739</td>\n",
       "      <td></td>\n",
       "      <td>1021316</td>\n",
       "      <td>8318</td>\n",
       "      <td>52462</td>\n",
       "      <td>1268</td>\n",
       "      <td>28600000</td>\n",
       "      <td>133894</td>\n",
       "      <td>213601044</td>\n",
       "      <td>South America</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russia</td>\n",
       "      <td>4351553</td>\n",
       "      <td></td>\n",
       "      <td>90275</td>\n",
       "      <td></td>\n",
       "      <td>3945527</td>\n",
       "      <td></td>\n",
       "      <td>315751</td>\n",
       "      <td>2300</td>\n",
       "      <td>29810</td>\n",
       "      <td>618</td>\n",
       "      <td>113800000</td>\n",
       "      <td>779571</td>\n",
       "      <td>145977728</td>\n",
       "      <td>Europe</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Other TotalCases NewCases TotalDeaths NewDeaths TotalRecovered  \\\n",
       "#                                                                          \n",
       "          World  118630045     8800     2631996       729       94238652   \n",
       "1           USA   29862124               542191                 20640270   \n",
       "2         India   11284311               158213                 10935803   \n",
       "3        Brazil   11205972               270917                  9913739   \n",
       "4        Russia    4351553                90275                  3945527   \n",
       "\n",
       "  NewRecovered ActiveCases Serious Critical Tot Cases/1M pop Deaths/1M pop  \\\n",
       "#                                                                            \n",
       "          6802    21759397            89790            15219         337.7   \n",
       "1                  8679663            12607            89854          1631   \n",
       "2                   190295             8944             8122           114   \n",
       "3                  1021316             8318            52462          1268   \n",
       "4                   315751             2300            29810           618   \n",
       "\n",
       "  TotalTests Tests/ 1M pop   Population      Continent 1 Caseevery X ppl  \n",
       "#                                                                         \n",
       "                                                   All                    \n",
       "1  373104726        1122655   332341490  North America                11  \n",
       "2  223479877         160853  1389345702           Asia               123  \n",
       "3   28600000         133894   213601044  South America                19  \n",
       "4  113800000         779571   145977728         Europe                34  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4283fe2577c4d4cee640e65e7667318ab3506080d3ed328026ef4e253cc24f8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
