{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'./data_fetching_part01.ipynb'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ikhalil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\magics\\execution.py:697\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    696\u001b[0m     fpath \u001b[39m=\u001b[39m arg_lst[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 697\u001b[0m     filename \u001b[39m=\u001b[39m file_finder(fpath)\n\u001b[0;32m    698\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ikhalil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\utils\\path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[39mreturn\u001b[39;00m py_name\n\u001b[1;32m---> 90\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile `\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m` not found.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n",
      "\u001b[1;31mOSError\u001b[0m: File `'./data_fetching_part01.ipynb'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1000\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# dti = pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01'),datetime.datetime(2018, 1, 1)])\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m./data_fetching_part01.ipynb # download latest data available\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m covid_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./alldays_data.csv\u001b[39m\u001b[39m'\u001b[39m, parse_dates\u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mLast_Update\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m date_parser \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime) \u001b[39m# adjust later code for parsing date here\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mdisplay\u001b[39;00m(\u001b[39mobject\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ikhalil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2367\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2368\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2369\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2371\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2372\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2373\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ikhalil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\magics\\execution.py:708\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39mmatch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m^\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\"\u001b[39m,fpath):\n\u001b[0;32m    707\u001b[0m         warn(\u001b[39m'\u001b[39m\u001b[39mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39mun \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmypath\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmyfile.py\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 708\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m     \u001b[39mif\u001b[39;00m fpath \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmeta_path:\n",
      "\u001b[1;31mException\u001b[0m: File `'./data_fetching_part01.ipynb'` not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pycountry_convert as pc\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "# dti = pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01'),datetime.datetime(2018, 1, 1)])\n",
    "covid_data = pd.read_csv('./alldays_data.csv', parse_dates= ['Last_Update'],\n",
    "date_parser = pd.to_datetime) # adjust later code for parsing date here\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing String columns \n",
    "* some errands \n",
    "* strip whitespaces \n",
    "* fillna province with country \n",
    "* fillna combined_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some errands\n",
    "some_corrections = {'Mainland China': 'China', 'US': 'USA', 'Korea, South': 'South Korea',\n",
    "                    'Taiwan*' : 'Taiwan', 'Congo (Kinshasa)' : \"Democratic Republic of the Congo\",\n",
    "                    \"Cote d'Ivoire\": \"Côte d'Ivoire\", \"Reunion\": \"Réunion\", 'UK': 'United Kingdom',\n",
    "                    'Congo (Brazzaville)': 'Republic of the Congo', 'Bahamas, The': 'Bahamas',\n",
    "                    'Gambia, The': 'Gambia', 'The Gambia': 'Gambia', 'West Bank and Gaza': 'Palestine',\n",
    "                    'Burma': \"Myanmar\", 'Timor-Leste': \"East Timor\", 'Republic of Korea': 'South Korea',\n",
    "                    'Iran (Islamic Republic of)': 'Iran', 'Viet Nam': 'Vietnam', 'Hong Kong SAR': 'Hong Kong',\n",
    "                    'Russian Federation': 'Russia', 'occupied Palestinian territory': 'Palestine',\n",
    "                     'The Bahamas': 'Bahamas', 'Macao SAR': 'Macau', 'Republic of Ireland': 'Ireland'}\n",
    "\n",
    "covid_data['Country'] = covid_data['Country'].replace(some_corrections)\n",
    "\n",
    "covid_data.loc[covid_data['Province']=='None', 'Province'] = np.nan\n",
    "# striping leading and trailing whitespaces from string variables\n",
    "covid_data[['Country', 'Province', 'Combined_Key']] = \\\n",
    "covid_data[['Country', 'Province', 'Combined_Key']].apply(lambda col: col.str.strip(), axis=0)\n",
    "# fillna provoince with name of country\n",
    "covid_data['Province'] = covid_data.apply(lambda x: x['Country'] if pd.isna(x['Province']) else x['Province'], axis = 1)\n",
    "def fillna_combined_key(row):\n",
    "    if pd.isna(row['Combined_Key']):\n",
    "         # fill with country if no province-level country, with country & province otherwise\n",
    "        row['Combined_Key'] = row['Country'] if row['Country'] == row['Province'] else row['Country'] + ', ' + row['Province']\n",
    "    return row\n",
    "\n",
    "covid_data = covid_data.apply(lambda row: fillna_combined_key(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found that JHU, source, used a more disaggregated reporting starting from 1st Feb in some countries e.g. USA, Canada, Australia. So decided to avoid the problem it might do to the way I got new cases from accumulated cases, by dropping all before 1st Feb except China which accounted for majority of cases at the time.\n",
    "\n",
    "covid_data = covid_data[(covid_data['Last_Update'] >= \"2020-02-01 00:00:00\") | covid_data['Country'].isin(['China', 'Macau', 'Hong Kong'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging data\n",
    "* Arranging Columns\n",
    "* two dataframes (Us vs Other World)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covid_data.columns = covid_data.columns.str.lower()\n",
    "covid_data.rename(columns = {'province': 'state', 'last_update': 'date', 'combined_key': 'location'}, inplace=True)\n",
    "covid_data = covid_data[['country', 'state', 'date', 'confirmed', 'deaths', 'recovered', 'active', 'location', 'fips']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Anhui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Chongqing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Fujian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Gansu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country      state                date  confirmed  deaths  recovered  \\\n",
       "0   China      Anhui 2020-01-22 17:00:00        1.0     NaN        NaN   \n",
       "1   China    Beijing 2020-01-22 17:00:00       14.0     NaN        NaN   \n",
       "2   China  Chongqing 2020-01-22 17:00:00        6.0     NaN        NaN   \n",
       "3   China     Fujian 2020-01-22 17:00:00        1.0     NaN        NaN   \n",
       "4   China      Gansu 2020-01-22 17:00:00        NaN     NaN        NaN   \n",
       "\n",
       "   active          location  \n",
       "0     NaN      China, Anhui  \n",
       "1     NaN    China, Beijing  \n",
       "2     NaN  China, Chongqing  \n",
       "3     NaN     China, Fujian  \n",
       "4     NaN      China, Gansu  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_world = covid_data[covid_data['country'] != 'USA'].copy()\n",
    "df_world = df_world.drop(columns = 'fips') # only relevant for USA\n",
    "df_world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_world = df_world.drop_duplicates(subset=['country', 'state', 'date'], keep='last') # per_day cases: last report each day if more than one\n",
    "# numeric columns\n",
    "num_cols = ['confirmed', 'deaths', 'recovered', 'active']\n",
    "df_world.loc[:, num_cols] = df_world.loc[:, num_cols].fillna(0)\n",
    "\n",
    "# # per day cases (confirmed, deaths) Note: original data is accumulated over time as far as I know\n",
    "# I guess there should be a better solution than looping on each group\n",
    "df_world.sort_values(by=['country', 'state', 'date'], inplace=True) # I think sort here is important \n",
    "df_world.reset_index(drop = True, inplace=True)\n",
    "grouped = df_world.groupby(['country', 'state'])\n",
    "all_data = []\n",
    "for _, group in grouped:\n",
    "    for col in num_cols[:-1]:\n",
    "        new_col = 'daily_' + col\n",
    "        group[new_col] = group[col].diff(1)\n",
    "        group.loc[group.index[0], new_col] = group.loc[group.index[0], col] # very first value the accumulated and daily col is same        \n",
    "    all_data.append(group)\n",
    "        \n",
    "df_world = pd.concat(all_data, sort=False, ignore_index=True)\n",
    "df_world.sort_values(by=['country', 'state', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Country Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per country cases\n",
    "#1st grouping to get country or country with state data (i.e. agg daily data and last of accumulated)\n",
    "per_country_cases = df_world.groupby(['country', 'state'], as_index=False).\\\n",
    "agg({'confirmed': 'last', 'deaths': 'last', 'recovered': 'last', 'active': 'median',\n",
    "     'daily_confirmed':'sum', 'daily_deaths': 'sum', 'daily_recovered': 'sum'}) \n",
    "#2nd grouping to get country level from states (won't harm no-state level data)\n",
    "per_country_cases = per_country_cases.groupby('country', as_index=False).sum()\n",
    "per_country_cases = per_country_cases[['country', 'confirmed', 'deaths', 'recovered', 'active']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>58730.0</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>52392.0</td>\n",
       "      <td>5273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>130409.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>105016.0</td>\n",
       "      <td>5295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>120736.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>84167.0</td>\n",
       "      <td>13555.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>13024.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>12458.0</td>\n",
       "      <td>413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>25492.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>23092.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  confirmed  deaths  recovered   active\n",
       "0  Afghanistan    58730.0  2572.0    52392.0   5273.0\n",
       "1      Albania   130409.0  2372.0   105016.0   5295.0\n",
       "2      Algeria   120736.0  3198.0    84167.0  13555.5\n",
       "3      Andorra    13024.0   124.0    12458.0    413.0\n",
       "4       Angola    25492.0   577.0    23092.0   1125.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_country_cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### daily cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_world['date'] = df_world['date'].dt.normalize() # drop unnecessary time part\n",
    "df_daily = df_world.groupby(['country', 'state', 'date'], as_index=False).sum()\n",
    "df_daily = df_daily[['country', 'state', 'date', 'daily_confirmed', 'daily_deaths', 'daily_recovered', 'active']]\n",
    "df_daily.rename(columns = {col: col[6:] for col in ['daily_confirmed', 'daily_deaths', 'daily_recovered']}, inplace=True)\n",
    "# dropping negative numbers from daily cases (I guess errors in reporting)\n",
    "df_daily.loc[df_daily['confirmed'] < 0, 'confirmed'] = np.nan\n",
    "df_daily.loc[df_daily['deaths'] < 0, 'deaths'] = np.nan\n",
    "df_daily.loc[df_daily['recovered'] < 0, 'recovered'] = np.nan\n",
    "df_daily.dropna(subset=['confirmed', 'deaths', 'recovered'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country        state       date  confirmed  deaths  recovered  active\n",
       "0  Afghanistan  Afghanistan 2020-02-24        1.0     0.0        0.0     0.0\n",
       "1  Afghanistan  Afghanistan 2020-03-08        3.0     0.0        0.0     0.0\n",
       "2  Afghanistan  Afghanistan 2020-03-10        1.0     0.0        0.0     0.0\n",
       "3  Afghanistan  Afghanistan 2020-03-11        2.0     0.0        0.0     0.0\n",
       "4  Afghanistan  Afghanistan 2020-03-14        4.0     0.0        0.0     0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding continent column\n",
    "* Better after aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Continent_code to Continent_names\n",
    "continents = {\n",
    "    'NA': 'North America',\n",
    "    'SA': 'South America', \n",
    "    'AS': 'Asia',\n",
    "    'OC': 'Australia',\n",
    "    'AF': 'Africa',\n",
    "    'EU' : 'Europe',\n",
    "    'na' : 'Others'\n",
    "}\n",
    "\n",
    "def country_to_continent_code(country):\n",
    "    try:\n",
    "        return pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(country))\n",
    "    except:\n",
    "        return \"na\"\n",
    "\n",
    "# insert continent column\n",
    "df_daily.insert(0, \"continent\", df_daily['country'].apply(lambda x: continents[country_to_continent_code(x)]))\n",
    "per_country_cases.insert(0, \"continent\", per_country_cases['country'].apply(lambda x: continents[country_to_continent_code(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per country cases: from worldometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>tests</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>59021</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>52489</td>\n",
       "      <td>3940</td>\n",
       "      <td>395439.0</td>\n",
       "      <td>39638567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Albania</td>\n",
       "      <td>130537</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>105728</td>\n",
       "      <td>22431</td>\n",
       "      <td>622711.0</td>\n",
       "      <td>2875230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>120922</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>84299</td>\n",
       "      <td>33416</td>\n",
       "      <td>230861.0</td>\n",
       "      <td>44493653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>13060</td>\n",
       "      <td>124.0</td>\n",
       "      <td>12491</td>\n",
       "      <td>445</td>\n",
       "      <td>193595.0</td>\n",
       "      <td>77366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Angola</td>\n",
       "      <td>25609</td>\n",
       "      <td>579.0</td>\n",
       "      <td>23092</td>\n",
       "      <td>1938</td>\n",
       "      <td>455499.0</td>\n",
       "      <td>33691594.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    continent      country  confirmed  deaths  recovered  active     tests  \\\n",
       "103      Asia  Afghanistan      59021  2592.0      52489    3940  395439.0   \n",
       "83     Europe      Albania     130537  2378.0     105728   22431  622711.0   \n",
       "84     Africa      Algeria     120922  3207.0      84299   33416  230861.0   \n",
       "137    Europe      Andorra      13060   124.0      12491     445  193595.0   \n",
       "120    Africa       Angola      25609   579.0      23092    1938  455499.0   \n",
       "\n",
       "     population  \n",
       "103  39638567.0  \n",
       "83    2875230.0  \n",
       "84   44493653.0  \n",
       "137     77366.0  \n",
       "120  33691594.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other = pd.read_csv('./world_worldometer.csv')\n",
    "columns = {'Continent': 'continent', 'Country Other':'country', 'TotalCases': 'confirmed', 'TotalDeaths': 'deaths',\n",
    "          'TotalRecovered': 'recovered', 'ActiveCases': 'active', 'TotalTests': 'tests', 'Population':'population'}\n",
    "df_other = df_other.rename(columns = columns)\n",
    "df_other = df_other[[col for _, col in columns.items()]]\n",
    "df_other = df_other[1:]\n",
    "df_other.sort_values('country', inplace=True)\n",
    "df_other.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USA\n",
    "* stopped working on it, it seems some data are cumulative, others are new cases, not sure how to handle\n",
    "* using worldometer data as a cross-section for latest USA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>active</th>\n",
       "      <th>tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>3732256</td>\n",
       "      <td>61479</td>\n",
       "      <td>1687173.0</td>\n",
       "      <td>59095717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2877774</td>\n",
       "      <td>50176</td>\n",
       "      <td>91177.0</td>\n",
       "      <td>27678766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2208584</td>\n",
       "      <td>34861</td>\n",
       "      <td>414122.0</td>\n",
       "      <td>27309151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>2077439</td>\n",
       "      <td>52242</td>\n",
       "      <td>585139.0</td>\n",
       "      <td>50361096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>1321033</td>\n",
       "      <td>24139</td>\n",
       "      <td>97476.0</td>\n",
       "      <td>22269555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      continent country       state  confirmed  deaths     active  \\\n",
       "1 2021-04-26  North America     USA  California    3732256   61479  1687173.0   \n",
       "2 2021-04-26  North America     USA       Texas    2877774   50176    91177.0   \n",
       "3 2021-04-26  North America     USA     Florida    2208584   34861   414122.0   \n",
       "4 2021-04-26  North America     USA    New York    2077439   52242   585139.0   \n",
       "5 2021-04-26  North America     USA    Illinois    1321033   24139    97476.0   \n",
       "\n",
       "      tests  \n",
       "1  59095717  \n",
       "2  27678766  \n",
       "3  27309151  \n",
       "4  50361096  \n",
       "5  22269555  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us = pd.read_csv('./usa_worldometer.csv')\n",
    "columns = {'USAState':'state', 'TotalCases': 'confirmed', 'TotalDeaths': 'deaths',\n",
    "          'ActiveCases': 'active', 'TotalTests': 'tests'}\n",
    "df_us = df_us.rename(columns = columns)\n",
    "df_us.insert(0, 'country', 'USA')\n",
    "df_us.insert(0, 'continent', 'North America')\n",
    "df_us.insert(0, 'date', pd.Timestamp.today().normalize())\n",
    "df_us = df_us[['date', 'continent', 'country', 'state', 'confirmed', 'deaths', 'active', 'tests']]\n",
    "df_us = df_us[1:]\n",
    "df_us.head() # can be used for state-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_row = df_us[['confirmed', 'deaths', 'active']].sum()\n",
    "us_row['country'] = 'USA'\n",
    "us_row['continent'] = 'North America'\n",
    "\n",
    "per_country_cases = per_country_cases.append(us_row, ignore_index=True, sort=False)\n",
    "per_country_cases.sort_values('country', inplace=True)\n",
    "df_daily = df_daily.append(df_us, sort=False, ignore_index=True)\n",
    "df_daily.sort_values(['country', 'state', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Cleaned Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: ./cleaned_data/allcountries_worldometer.csv\n",
      "Successfully saved: ./cleaned_data/per_country_aggregate.csv\n",
      "Successfully saved: ./cleaned_data/daily_disagg.csv\n",
      "Successfully saved: ./cleaned_data/usa_states.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('./cleaned_data'):\n",
    "    os.mkdir('cleaned_data')\n",
    "per_country_cases.to_csv('./cleaned_data/per_country_aggregate.csv', index=False)\n",
    "df_other.to_csv('./cleaned_data/allcountries_worldometer.csv', index=False)\n",
    "print('Successfully saved: ./cleaned_data/allcountries_worldometer.csv')\n",
    "print('Successfully saved: ./cleaned_data/per_country_aggregate.csv')\n",
    "df_daily.to_csv('./cleaned_data/daily_disagg.csv', index=False)\n",
    "print('Successfully saved: ./cleaned_data/daily_disagg.csv')\n",
    "df_us.to_csv('./cleaned_data/usa_states.csv', index=False)\n",
    "print('Successfully saved: ./cleaned_data/usa_states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4283fe2577c4d4cee640e65e7667318ab3506080d3ed328026ef4e253cc24f8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
