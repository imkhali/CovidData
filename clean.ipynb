{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: 08-16-2021.csv\n",
      "Successfully saved: 08-17-2021.csv\n",
      "Successfully saved: 08-18-2021.csv\n",
      "Successfully saved: 08-19-2021.csv\n",
      "Successfully saved: 08-20-2021.csv\n",
      "Successfully saved: 08-21-2021.csv\n",
      "Successfully saved: 08-22-2021.csv\n",
      "Successfully saved: 08-23-2021.csv\n",
      "Successfully saved: 08-24-2021.csv\n",
      "Successfully saved: 08-25-2021.csv\n",
      "Successfully saved: 08-26-2021.csv\n",
      "Successfully saved: 08-27-2021.csv\n",
      "Successfully saved: 08-28-2021.csv\n",
      "Successfully saved: 08-29-2021.csv\n",
      "Successfully saved: 08-30-2021.csv\n",
      "Successfully saved: 08-31-2021.csv\n",
      "Successfully saved: 09-01-2021.csv\n",
      "Successfully saved: 09-02-2021.csv\n",
      "Successfully saved: 09-03-2021.csv\n",
      "Successfully saved: 09-04-2021.csv\n",
      "Successfully saved: 09-05-2021.csv\n",
      "Successfully saved: 09-06-2021.csv\n",
      "Successfully saved: 09-07-2021.csv\n",
      "Successfully saved: 09-08-2021.csv\n",
      "Successfully saved: 09-09-2021.csv\n",
      "Successfully saved: 09-10-2021.csv\n",
      "Successfully saved: 09-11-2021.csv\n",
      "Successfully saved: 09-12-2021.csv\n",
      "Successfully saved: 09-13-2021.csv\n",
      "Successfully saved: 09-14-2021.csv\n",
      "Successfully saved: 09-15-2021.csv\n",
      "Successfully saved: 09-16-2021.csv\n",
      "Successfully saved: 09-17-2021.csv\n",
      "Successfully saved: 09-18-2021.csv\n",
      "Successfully saved: 09-19-2021.csv\n",
      "Successfully saved: 09-20-2021.csv\n",
      "Successfully saved: 09-21-2021.csv\n",
      "Successfully saved: 09-22-2021.csv\n",
      "Successfully saved: 09-23-2021.csv\n",
      "Successfully saved: 09-24-2021.csv\n",
      "Successfully saved: 09-25-2021.csv\n",
      "Successfully saved: 09-26-2021.csv\n",
      "Successfully saved: 09-27-2021.csv\n",
      "Successfully saved: 09-28-2021.csv\n",
      "Successfully saved: 09-29-2021.csv\n",
      "Successfully saved: 09-30-2021.csv\n",
      "Successfully saved: 10-01-2021.csv\n",
      "Successfully saved: 10-02-2021.csv\n",
      "Successfully saved: 10-03-2021.csv\n",
      "Successfully saved: 10-04-2021.csv\n",
      "Successfully saved: 10-05-2021.csv\n",
      "Successfully saved: 10-06-2021.csv\n",
      "Successfully saved: 10-07-2021.csv\n",
      "Successfully saved: 10-08-2021.csv\n",
      "Successfully saved: 10-09-2021.csv\n",
      "Successfully saved: 10-10-2021.csv\n",
      "Successfully saved: 10-11-2021.csv\n",
      "Successfully saved: 10-12-2021.csv\n",
      "Successfully saved: 10-13-2021.csv\n",
      "Successfully saved: 10-14-2021.csv\n",
      "Successfully saved: 10-15-2021.csv\n",
      "Successfully saved: 10-16-2021.csv\n",
      "Successfully saved: 10-17-2021.csv\n",
      "Successfully saved: 10-18-2021.csv\n",
      "Successfully saved: 10-19-2021.csv\n",
      "Successfully saved: 10-20-2021.csv\n",
      "Successfully saved: 10-21-2021.csv\n",
      "Successfully saved: 10-22-2021.csv\n",
      "Successfully saved: 10-23-2021.csv\n",
      "Successfully saved: 10-24-2021.csv\n",
      "Successfully saved: 10-25-2021.csv\n",
      "Successfully saved: 10-26-2021.csv\n",
      "Successfully saved: 10-27-2021.csv\n",
      "Successfully saved: 10-28-2021.csv\n",
      "Successfully saved: 10-29-2021.csv\n",
      "Successfully saved: 10-30-2021.csv\n",
      "Successfully saved: 10-31-2021.csv\n",
      "Successfully saved: 11-01-2021.csv\n",
      "Successfully saved: 11-02-2021.csv\n",
      "Successfully saved: 11-03-2021.csv\n",
      "Successfully saved: 11-04-2021.csv\n",
      "Successfully saved: 11-05-2021.csv\n",
      "Successfully saved: 11-06-2021.csv\n",
      "Successfully saved: 11-07-2021.csv\n",
      "Successfully saved: 11-08-2021.csv\n",
      "Successfully saved: 11-09-2021.csv\n",
      "Successfully saved: 11-10-2021.csv\n",
      "Successfully saved: 11-11-2021.csv\n",
      "Successfully saved: 11-12-2021.csv\n",
      "Successfully saved: 11-13-2021.csv\n",
      "Successfully saved: 11-14-2021.csv\n",
      "Successfully saved: 11-15-2021.csv\n",
      "Successfully saved: 11-16-2021.csv\n",
      "Successfully saved: 11-17-2021.csv\n",
      "Successfully saved: 11-18-2021.csv\n",
      "Successfully saved: 11-19-2021.csv\n",
      "Successfully saved: 11-20-2021.csv\n",
      "Successfully saved: 11-21-2021.csv\n",
      "Successfully saved: 11-22-2021.csv\n",
      "Successfully saved: 11-23-2021.csv\n",
      "Successfully saved: 11-24-2021.csv\n",
      "Successfully saved: 11-25-2021.csv\n",
      "Successfully saved: 11-26-2021.csv\n",
      "Successfully saved: 11-27-2021.csv\n",
      "Successfully saved: 11-28-2021.csv\n",
      "Successfully saved: 11-29-2021.csv\n",
      "Successfully saved: 11-30-2021.csv\n",
      "Successfully saved: 12-01-2021.csv\n",
      "Successfully saved: 12-02-2021.csv\n",
      "Successfully saved: 12-03-2021.csv\n",
      "Successfully saved: 12-04-2021.csv\n",
      "Successfully saved: 12-05-2021.csv\n",
      "Successfully saved: 12-06-2021.csv\n",
      "Successfully saved: 12-07-2021.csv\n",
      "Successfully saved: 12-08-2021.csv\n",
      "Successfully saved: 12-09-2021.csv\n",
      "Successfully saved: 12-10-2021.csv\n",
      "Successfully saved: 12-11-2021.csv\n",
      "Successfully saved: 12-12-2021.csv\n",
      "Successfully saved: 12-13-2021.csv\n",
      "Successfully saved: 12-14-2021.csv\n",
      "Successfully saved: 12-15-2021.csv\n",
      "Successfully saved: 12-16-2021.csv\n",
      "Successfully saved: 12-17-2021.csv\n",
      "Successfully saved: 12-18-2021.csv\n",
      "Successfully saved: 12-19-2021.csv\n",
      "Successfully saved: 12-20-2021.csv\n",
      "Successfully saved: 12-21-2021.csv\n",
      "Successfully saved: 12-22-2021.csv\n",
      "Successfully saved: 12-23-2021.csv\n",
      "Successfully saved: 12-24-2021.csv\n",
      "Successfully saved: 12-25-2021.csv\n",
      "Successfully saved: 12-26-2021.csv\n",
      "Successfully saved: 12-27-2021.csv\n",
      "Successfully saved: 12-28-2021.csv\n",
      "Successfully saved: 12-29-2021.csv\n",
      "Successfully saved: 12-30-2021.csv\n",
      "Successfully saved: 12-31-2021.csv\n",
      "Successfully saved: 01-01-2022.csv\n",
      "Successfully saved: 01-02-2022.csv\n",
      "Successfully saved: 01-03-2022.csv\n",
      "Successfully saved: 01-04-2022.csv\n",
      "Successfully saved: 01-05-2022.csv\n",
      "Successfully saved: 01-06-2022.csv\n",
      "Successfully saved: 01-07-2022.csv\n",
      "Successfully saved: 01-08-2022.csv\n",
      "Successfully saved: 01-09-2022.csv\n",
      "Successfully saved: 01-10-2022.csv\n",
      "Successfully saved: 01-11-2022.csv\n",
      "Successfully saved: 01-12-2022.csv\n",
      "Successfully saved: 01-13-2022.csv\n",
      "Successfully saved: 01-14-2022.csv\n",
      "Successfully saved: 01-15-2022.csv\n",
      "Successfully saved: 01-16-2022.csv\n",
      "Successfully saved: 01-17-2022.csv\n",
      "Successfully saved: 01-18-2022.csv\n",
      "Successfully saved: 01-19-2022.csv\n",
      "Successfully saved: 01-20-2022.csv\n",
      "Successfully saved: 01-21-2022.csv\n",
      "Successfully saved: 01-22-2022.csv\n",
      "Successfully saved: 01-23-2022.csv\n",
      "Successfully saved: 01-24-2022.csv\n",
      "Successfully saved: 01-25-2022.csv\n",
      "Successfully saved: 01-26-2022.csv\n",
      "Successfully saved: 01-27-2022.csv\n",
      "Successfully saved: 01-28-2022.csv\n",
      "Successfully saved: 01-29-2022.csv\n",
      "Successfully saved: 01-30-2022.csv\n",
      "Successfully saved: 01-31-2022.csv\n",
      "Successfully saved: 02-01-2022.csv\n",
      "Successfully saved: 02-02-2022.csv\n",
      "Successfully saved: 02-03-2022.csv\n",
      "Successfully saved: 02-04-2022.csv\n",
      "Successfully saved: 02-05-2022.csv\n",
      "Successfully saved: 02-06-2022.csv\n",
      "Successfully saved: 02-07-2022.csv\n",
      "Successfully saved: 02-08-2022.csv\n",
      "Successfully saved: 02-09-2022.csv\n",
      "Successfully saved: 02-10-2022.csv\n",
      "Successfully saved: 02-11-2022.csv\n",
      "Successfully saved: 02-12-2022.csv\n",
      "Successfully saved: 02-13-2022.csv\n",
      "Successfully saved: 02-14-2022.csv\n",
      "Successfully saved: 02-15-2022.csv\n",
      "Successfully saved: 02-16-2022.csv\n",
      "Successfully saved: 02-17-2022.csv\n",
      "Successfully saved: 02-18-2022.csv\n",
      "Successfully saved: 02-19-2022.csv\n",
      "Successfully saved: 02-20-2022.csv\n",
      "Successfully saved: 02-21-2022.csv\n",
      "Successfully saved: 02-22-2022.csv\n",
      "Successfully saved: 02-23-2022.csv\n",
      "Successfully saved: 02-24-2022.csv\n",
      "Successfully saved: 02-25-2022.csv\n",
      "Successfully saved: 02-26-2022.csv\n",
      "Successfully saved: 02-27-2022.csv\n",
      "Successfully saved: 02-28-2022.csv\n",
      "Successfully saved: 03-01-2022.csv\n",
      "Successfully saved: 03-02-2022.csv\n",
      "Successfully saved: 03-03-2022.csv\n",
      "Successfully saved: 03-04-2022.csv\n",
      "Successfully saved: 03-05-2022.csv\n",
      "Successfully saved: 03-06-2022.csv\n",
      "Successfully saved: 03-07-2022.csv\n",
      "Successfully saved: 03-08-2022.csv\n",
      "Successfully saved: 03-09-2022.csv\n",
      "Successfully saved: 03-10-2022.csv\n",
      "Successfully saved: 03-11-2022.csv\n",
      "Successfully saved: 03-12-2022.csv\n",
      "Successfully saved: 03-13-2022.csv\n",
      "Successfully saved: 03-14-2022.csv\n",
      "Successfully saved: 03-15-2022.csv\n",
      "Successfully saved: 03-16-2022.csv\n",
      "Successfully saved: 03-17-2022.csv\n",
      "Successfully saved: 03-18-2022.csv\n",
      "Successfully saved: 03-19-2022.csv\n",
      "Successfully saved: 03-20-2022.csv\n",
      "Successfully saved: 03-21-2022.csv\n",
      "Successfully saved: 03-22-2022.csv\n",
      "Successfully saved: 03-23-2022.csv\n",
      "Successfully saved: 03-24-2022.csv\n",
      "Successfully saved: 03-25-2022.csv\n",
      "Successfully saved: 03-26-2022.csv\n",
      "Successfully saved: 03-27-2022.csv\n",
      "Successfully saved: 03-28-2022.csv\n",
      "Successfully saved: 03-29-2022.csv\n",
      "Successfully saved: 03-30-2022.csv\n",
      "Successfully saved: 03-31-2022.csv\n",
      "Successfully saved: 04-01-2022.csv\n",
      "Successfully saved: 04-02-2022.csv\n",
      "Successfully saved: 04-03-2022.csv\n",
      "Successfully saved: 04-04-2022.csv\n",
      "Successfully saved: 04-05-2022.csv\n",
      "Successfully saved: 04-06-2022.csv\n",
      "Successfully saved: 04-07-2022.csv\n",
      "Successfully saved: 04-08-2022.csv\n",
      "No Covid data file for 04-09-2022\n",
      "Successfully updated alldays_data.csv\n",
      "Successsfully saved: usa_worldometer.csv\n",
      "Successsfully saved: world_worldometer.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khalil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pycountry_convert as pc\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "# dti = pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01'),datetime.datetime(2018, 1, 1)])\n",
    "%run ./data_fetching_part01.ipynb # download latest data available\n",
    "covid_data = pd.read_csv('./alldays_data.csv', parse_dates= ['Last_Update'],\n",
    "date_parser = pd.to_datetime) # adjust later code for parsing date here\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing String columns \n",
    "* some errands \n",
    "* strip whitespaces \n",
    "* fillna province with country \n",
    "* fillna combined_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some errands\n",
    "some_corrections = {'Mainland China': 'China', 'US': 'USA', 'Korea, South': 'South Korea',\n",
    "                    'Taiwan*' : 'Taiwan', 'Congo (Kinshasa)' : \"Democratic Republic of the Congo\",\n",
    "                    \"Cote d'Ivoire\": \"Côte d'Ivoire\", \"Reunion\": \"Réunion\", 'UK': 'United Kingdom',\n",
    "                    'Congo (Brazzaville)': 'Republic of the Congo', 'Bahamas, The': 'Bahamas',\n",
    "                    'Gambia, The': 'Gambia', 'The Gambia': 'Gambia', 'West Bank and Gaza': 'Palestine',\n",
    "                    'Burma': \"Myanmar\", 'Timor-Leste': \"East Timor\", 'Republic of Korea': 'South Korea',\n",
    "                    'Iran (Islamic Republic of)': 'Iran', 'Viet Nam': 'Vietnam', 'Hong Kong SAR': 'Hong Kong',\n",
    "                    'Russian Federation': 'Russia', 'occupied Palestinian territory': 'Palestine',\n",
    "                     'The Bahamas': 'Bahamas', 'Macao SAR': 'Macau', 'Republic of Ireland': 'Ireland'}\n",
    "\n",
    "covid_data['Country'] = covid_data['Country'].replace(some_corrections)\n",
    "\n",
    "covid_data.loc[covid_data['Province']=='None', 'Province'] = np.nan\n",
    "# striping leading and trailing whitespaces from string variables\n",
    "covid_data[['Country', 'Province', 'Combined_Key']] = \\\n",
    "covid_data[['Country', 'Province', 'Combined_Key']].apply(lambda col: col.str.strip(), axis=0)\n",
    "# fillna provoince with name of country\n",
    "covid_data['Province'] = covid_data.apply(lambda x: x['Country'] if pd.isna(x['Province']) else x['Province'], axis = 1)\n",
    "def fillna_combined_key(row):\n",
    "    if pd.isna(row['Combined_Key']):\n",
    "         # fill with country if no province-level country, with country & province otherwise\n",
    "        row['Combined_Key'] = row['Country'] if row['Country'] == row['Province'] else row['Country'] + ', ' + row['Province']\n",
    "    return row\n",
    "\n",
    "covid_data = covid_data.apply(lambda row: fillna_combined_key(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found that JHU, source, used a more disaggregated reporting starting from 1st Feb in some countries e.g. USA, Canada, Australia. So decided to avoid the problem it might do to the way I got new cases from accumulated cases, by dropping all before 1st Feb except China which accounted for majority of cases at the time.\n",
    "\n",
    "covid_data = covid_data[(covid_data['Last_Update'] >= \"2020-02-01 00:00:00\") | covid_data['Country'].isin(['China', 'Macau', 'Hong Kong'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging data\n",
    "* Arranging Columns\n",
    "* two dataframes (Us vs Other World)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covid_data.columns = covid_data.columns.str.lower()\n",
    "covid_data.rename(columns = {'province': 'state', 'last_update': 'date', 'combined_key': 'location'}, inplace=True)\n",
    "covid_data = covid_data[['country', 'state', 'date', 'confirmed', 'deaths', 'recovered', 'active', 'location', 'fips']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Anhui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Chongqing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Fujian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>2020-01-22 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China, Gansu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country      state                date  confirmed  deaths  recovered  \\\n",
       "0   China      Anhui 2020-01-22 17:00:00        1.0     NaN        NaN   \n",
       "1   China    Beijing 2020-01-22 17:00:00       14.0     NaN        NaN   \n",
       "2   China  Chongqing 2020-01-22 17:00:00        6.0     NaN        NaN   \n",
       "3   China     Fujian 2020-01-22 17:00:00        1.0     NaN        NaN   \n",
       "4   China      Gansu 2020-01-22 17:00:00        NaN     NaN        NaN   \n",
       "\n",
       "   active          location  \n",
       "0     NaN      China, Anhui  \n",
       "1     NaN    China, Beijing  \n",
       "2     NaN  China, Chongqing  \n",
       "3     NaN     China, Fujian  \n",
       "4     NaN      China, Gansu  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_world = covid_data[covid_data['country'] != 'USA'].copy()\n",
    "df_world = df_world.drop(columns = 'fips') # only relevant for USA\n",
    "df_world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_world = df_world.drop_duplicates(subset=['country', 'state', 'date'], keep='last') # per_day cases: last report each day if more than one\n",
    "# numeric columns\n",
    "num_cols = ['confirmed', 'deaths', 'recovered', 'active']\n",
    "df_world.loc[:, num_cols] = df_world.loc[:, num_cols].fillna(0)\n",
    "\n",
    "# # per day cases (confirmed, deaths) Note: original data is accumulated over time as far as I know\n",
    "# I guess there should be a better solution than looping on each group\n",
    "df_world.sort_values(by=['country', 'state', 'date'], inplace=True) # I think sort here is important \n",
    "df_world.reset_index(drop = True, inplace=True)\n",
    "grouped = df_world.groupby(['country', 'state'])\n",
    "all_data = []\n",
    "for _, group in grouped:\n",
    "    for col in num_cols[:-1]:\n",
    "        new_col = 'daily_' + col\n",
    "        group[new_col] = group[col].diff(1)\n",
    "        group.loc[group.index[0], new_col] = group.loc[group.index[0], col] # very first value the accumulated and daily col is same        \n",
    "    all_data.append(group)\n",
    "        \n",
    "df_world = pd.concat(all_data, sort=False, ignore_index=True)\n",
    "df_world.sort_values(by=['country', 'state', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Country Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per country cases\n",
    "#1st grouping to get country or country with state data (i.e. agg daily data and last of accumulated)\n",
    "per_country_cases = df_world.groupby(['country', 'state'], as_index=False).\\\n",
    "agg({'confirmed': 'last', 'deaths': 'last', 'recovered': 'last', 'active': 'median',\n",
    "     'daily_confirmed':'sum', 'daily_deaths': 'sum', 'daily_recovered': 'sum'}) \n",
    "#2nd grouping to get country level from states (won't harm no-state level data)\n",
    "per_country_cases = per_country_cases.groupby('country', as_index=False).sum()\n",
    "per_country_cases = per_country_cases[['country', 'confirmed', 'deaths', 'recovered', 'active']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>58730.0</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>52392.0</td>\n",
       "      <td>5273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>130409.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>105016.0</td>\n",
       "      <td>5295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>120736.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>84167.0</td>\n",
       "      <td>13555.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>13024.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>12458.0</td>\n",
       "      <td>413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>25492.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>23092.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  confirmed  deaths  recovered   active\n",
       "0  Afghanistan    58730.0  2572.0    52392.0   5273.0\n",
       "1      Albania   130409.0  2372.0   105016.0   5295.0\n",
       "2      Algeria   120736.0  3198.0    84167.0  13555.5\n",
       "3      Andorra    13024.0   124.0    12458.0    413.0\n",
       "4       Angola    25492.0   577.0    23092.0   1125.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_country_cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### daily cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_world['date'] = df_world['date'].dt.normalize() # drop unnecessary time part\n",
    "df_daily = df_world.groupby(['country', 'state', 'date'], as_index=False).sum()\n",
    "df_daily = df_daily[['country', 'state', 'date', 'daily_confirmed', 'daily_deaths', 'daily_recovered', 'active']]\n",
    "df_daily.rename(columns = {col: col[6:] for col in ['daily_confirmed', 'daily_deaths', 'daily_recovered']}, inplace=True)\n",
    "# dropping negative numbers from daily cases (I guess errors in reporting)\n",
    "df_daily.loc[df_daily['confirmed'] < 0, 'confirmed'] = np.nan\n",
    "df_daily.loc[df_daily['deaths'] < 0, 'deaths'] = np.nan\n",
    "df_daily.loc[df_daily['recovered'] < 0, 'recovered'] = np.nan\n",
    "df_daily.dropna(subset=['confirmed', 'deaths', 'recovered'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country        state       date  confirmed  deaths  recovered  active\n",
       "0  Afghanistan  Afghanistan 2020-02-24        1.0     0.0        0.0     0.0\n",
       "1  Afghanistan  Afghanistan 2020-03-08        3.0     0.0        0.0     0.0\n",
       "2  Afghanistan  Afghanistan 2020-03-10        1.0     0.0        0.0     0.0\n",
       "3  Afghanistan  Afghanistan 2020-03-11        2.0     0.0        0.0     0.0\n",
       "4  Afghanistan  Afghanistan 2020-03-14        4.0     0.0        0.0     0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding continent column\n",
    "* Better after aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Continent_code to Continent_names\n",
    "continents = {\n",
    "    'NA': 'North America',\n",
    "    'SA': 'South America', \n",
    "    'AS': 'Asia',\n",
    "    'OC': 'Australia',\n",
    "    'AF': 'Africa',\n",
    "    'EU' : 'Europe',\n",
    "    'na' : 'Others'\n",
    "}\n",
    "\n",
    "def country_to_continent_code(country):\n",
    "    try:\n",
    "        return pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(country))\n",
    "    except:\n",
    "        return \"na\"\n",
    "\n",
    "# insert continent column\n",
    "df_daily.insert(0, \"continent\", df_daily['country'].apply(lambda x: continents[country_to_continent_code(x)]))\n",
    "per_country_cases.insert(0, \"continent\", per_country_cases['country'].apply(lambda x: continents[country_to_continent_code(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per country cases: from worldometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>tests</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>59021</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>52489</td>\n",
       "      <td>3940</td>\n",
       "      <td>395439.0</td>\n",
       "      <td>39638567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Albania</td>\n",
       "      <td>130537</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>105728</td>\n",
       "      <td>22431</td>\n",
       "      <td>622711.0</td>\n",
       "      <td>2875230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>120922</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>84299</td>\n",
       "      <td>33416</td>\n",
       "      <td>230861.0</td>\n",
       "      <td>44493653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>13060</td>\n",
       "      <td>124.0</td>\n",
       "      <td>12491</td>\n",
       "      <td>445</td>\n",
       "      <td>193595.0</td>\n",
       "      <td>77366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Angola</td>\n",
       "      <td>25609</td>\n",
       "      <td>579.0</td>\n",
       "      <td>23092</td>\n",
       "      <td>1938</td>\n",
       "      <td>455499.0</td>\n",
       "      <td>33691594.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    continent      country  confirmed  deaths  recovered  active     tests  \\\n",
       "103      Asia  Afghanistan      59021  2592.0      52489    3940  395439.0   \n",
       "83     Europe      Albania     130537  2378.0     105728   22431  622711.0   \n",
       "84     Africa      Algeria     120922  3207.0      84299   33416  230861.0   \n",
       "137    Europe      Andorra      13060   124.0      12491     445  193595.0   \n",
       "120    Africa       Angola      25609   579.0      23092    1938  455499.0   \n",
       "\n",
       "     population  \n",
       "103  39638567.0  \n",
       "83    2875230.0  \n",
       "84   44493653.0  \n",
       "137     77366.0  \n",
       "120  33691594.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other = pd.read_csv('./world_worldometer.csv')\n",
    "columns = {'Continent': 'continent', 'Country Other':'country', 'TotalCases': 'confirmed', 'TotalDeaths': 'deaths',\n",
    "          'TotalRecovered': 'recovered', 'ActiveCases': 'active', 'TotalTests': 'tests', 'Population':'population'}\n",
    "df_other = df_other.rename(columns = columns)\n",
    "df_other = df_other[[col for _, col in columns.items()]]\n",
    "df_other = df_other[1:]\n",
    "df_other.sort_values('country', inplace=True)\n",
    "df_other.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USA\n",
    "* stopped working on it, it seems some data are cumulative, others are new cases, not sure how to handle\n",
    "* using worldometer data as a cross-section for latest USA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>active</th>\n",
       "      <th>tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>3732256</td>\n",
       "      <td>61479</td>\n",
       "      <td>1687173.0</td>\n",
       "      <td>59095717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2877774</td>\n",
       "      <td>50176</td>\n",
       "      <td>91177.0</td>\n",
       "      <td>27678766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2208584</td>\n",
       "      <td>34861</td>\n",
       "      <td>414122.0</td>\n",
       "      <td>27309151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>2077439</td>\n",
       "      <td>52242</td>\n",
       "      <td>585139.0</td>\n",
       "      <td>50361096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>1321033</td>\n",
       "      <td>24139</td>\n",
       "      <td>97476.0</td>\n",
       "      <td>22269555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      continent country       state  confirmed  deaths     active  \\\n",
       "1 2021-04-26  North America     USA  California    3732256   61479  1687173.0   \n",
       "2 2021-04-26  North America     USA       Texas    2877774   50176    91177.0   \n",
       "3 2021-04-26  North America     USA     Florida    2208584   34861   414122.0   \n",
       "4 2021-04-26  North America     USA    New York    2077439   52242   585139.0   \n",
       "5 2021-04-26  North America     USA    Illinois    1321033   24139    97476.0   \n",
       "\n",
       "      tests  \n",
       "1  59095717  \n",
       "2  27678766  \n",
       "3  27309151  \n",
       "4  50361096  \n",
       "5  22269555  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us = pd.read_csv('./usa_worldometer.csv')\n",
    "columns = {'USAState':'state', 'TotalCases': 'confirmed', 'TotalDeaths': 'deaths',\n",
    "          'ActiveCases': 'active', 'TotalTests': 'tests'}\n",
    "df_us = df_us.rename(columns = columns)\n",
    "df_us.insert(0, 'country', 'USA')\n",
    "df_us.insert(0, 'continent', 'North America')\n",
    "df_us.insert(0, 'date', pd.Timestamp.today().normalize())\n",
    "df_us = df_us[['date', 'continent', 'country', 'state', 'confirmed', 'deaths', 'active', 'tests']]\n",
    "df_us = df_us[1:]\n",
    "df_us.head() # can be used for state-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_row = df_us[['confirmed', 'deaths', 'active']].sum()\n",
    "us_row['country'] = 'USA'\n",
    "us_row['continent'] = 'North America'\n",
    "\n",
    "per_country_cases = per_country_cases.append(us_row, ignore_index=True, sort=False)\n",
    "per_country_cases.sort_values('country', inplace=True)\n",
    "df_daily = df_daily.append(df_us, sort=False, ignore_index=True)\n",
    "df_daily.sort_values(['country', 'state', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Cleaned Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: ./cleaned_data/allcountries_worldometer.csv\n",
      "Successfully saved: ./cleaned_data/per_country_aggregate.csv\n",
      "Successfully saved: ./cleaned_data/daily_disagg.csv\n",
      "Successfully saved: ./cleaned_data/usa_states.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('./cleaned_data'):\n",
    "    os.mkdir('cleaned_data')\n",
    "per_country_cases.to_csv('./cleaned_data/per_country_aggregate.csv', index=False)\n",
    "df_other.to_csv('./cleaned_data/allcountries_worldometer.csv', index=False)\n",
    "print('Successfully saved: ./cleaned_data/allcountries_worldometer.csv')\n",
    "print('Successfully saved: ./cleaned_data/per_country_aggregate.csv')\n",
    "df_daily.to_csv('./cleaned_data/daily_disagg.csv', index=False)\n",
    "print('Successfully saved: ./cleaned_data/daily_disagg.csv')\n",
    "df_us.to_csv('./cleaned_data/usa_states.csv', index=False)\n",
    "print('Successfully saved: ./cleaned_data/usa_states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   ------------------------------ DRAFT ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### maybe not needed after fillna state\n",
    "# #knowing which countries have province level data\n",
    "# countries = covid_data['country'].unique()\n",
    "# cntry_level = []\n",
    "# province_level = []\n",
    "# for cntry in countries:\n",
    "#     filt = (covid_data['country'] == cntry)\n",
    "#     only_cntry_level = covid_data.loc[filt, 'Province'].isna().all()\n",
    "#     if only_cntry_level:\n",
    "#         cntry_level.append(cntry)\n",
    "#     else:\n",
    "#         province_level.append(cntry)\n",
    "\n",
    "# province_level.remove('USA')    # has different data source, look below\n",
    "# #province_level.remove('Macao SAR')\n",
    "# province_level.remove('Macau')\n",
    "# province_level.remove('Taipei and environs')\n",
    "# province_level.remove('Taiwan')\n",
    "# cntry_level.append('Taiwan')\n",
    "# province_level.remove('Hong Kong')\n",
    "# cntry_level.append('Hong Kong')\n",
    "# province_level.remove('Israel')\n",
    "# cntry_level.append('Israel')\n",
    "# province_level.remove('Cruise Ship')\n",
    "# province_level.remove('Others')\n",
    "\n",
    "    \n",
    "# print('Counties with no province data: \\n', sorted(cntry_level), \n",
    "#     '\\n\\n', 'Countries with province data: \\n', sorted(province_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function return data per country for countries with no subnational levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def covid_by_country(country_='Egypt'):\n",
    "#     \"\"\" return a dataframe of daily cases in country_\"\"\"\n",
    "#     if country_ in cntry_level:\n",
    "#         covid_country = covid_data.loc[covid_data['Country']==country_]\n",
    "#         covid_country.sort_values(by='Date', inplace=True, ignore_index=True)\n",
    "#         covid_country['report_id'] = covid_country.groupby('Date').ngroup()\n",
    "#         #old way\n",
    "#         # covid_country['report_id'] = covid_country.groupby('Date').cumcount()==0).astype(int).cumsum()\n",
    "#         covid_country = covid_country.groupby('report_id').tail(1) # last update within a day nth(-1) or nth([-1])\n",
    "#         # covid_country = covid_country.groupby([pd.Grouper(freq='1d', key='date')]).tail() # if 'date' is datetime not object\n",
    "#         covid_country.rename(columns={'Confirmed':'AccConfirmed',\n",
    "#                             'Deaths': 'AccDeaths', 'Recovered':'AccRecovered'}, inplace=True)\n",
    "#         covid_country.set_index('Date', inplace=True)\n",
    "\n",
    "#         covid_country['confirmed'] = covid_country['AccConfirmed'].diff(1)\n",
    "#         covid_country.loc[covid_country.index[0], 'confirmed'] = covid_country.loc[covid_country.index[0], 'AccConfirmed']\n",
    "#         covid_country['deaths'] = covid_country['AccDeaths'].diff(1)\n",
    "#         covid_country.loc[covid_country.index[0], 'deaths'] = covid_country.loc[covid_country.index[0], 'AccDeaths']\n",
    "#         covid_country['recovered'] = covid_country['AccRecovered'].diff(1)\n",
    "#         covid_country.loc[covid_country.index[0], 'recovered'] = covid_country.loc[covid_country.index[0], 'AccRecovered']\n",
    "\n",
    "#         covid_country.loc[covid_country['confirmed'] < 0, 'confirmed'] = np.nan\n",
    "#         covid_country.loc[covid_country['deaths'] < 0, 'deaths'] = np.nan\n",
    "#         covid_country.loc[covid_country['recovered'] < 0, 'recovered'] = np.nan\n",
    "\n",
    "#         covid_country.dropna(thresh=2, inplace=True, subset=['AccConfirmed', 'AccDeaths',\n",
    "#                                             'AccRecovered', 'confirmed', 'deaths', 'recovered'])\n",
    "#         covid_country = covid_country.reindex(columns = ['AccConfirmed', 'AccDeaths', 'AccRecovered', 'confirmed', 'deaths', 'recovered', 'Latitude', 'Longitude'])\n",
    "\n",
    "#         return covid_country\n",
    "\n",
    "# egy_covid = covid_by_country()\n",
    "# egy_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# egy_covid.groupby('Date').expanding().agg('count') # check later to create id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function return data per country for countries with subnational levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def covid_by_country_with_states(country_='Australia'):\n",
    "#     \"\"\" return a dataframe of daily cases in country_\"\"\"\n",
    "#     if country_ in province_level:\n",
    "#         covid_country = covid_data.loc[covid_data['Country']==country_]\n",
    "#         # a placeholder for nan in provinces\n",
    "#         covid_country['Province']=covid_country.apply(lambda x: x['Country'] if pd.isnull(x['Province']) else x['Province'],axis=1)\n",
    "        \n",
    "#         covid_country.sort_values(by=['Province', 'Date'], inplace=True)\n",
    "#         covid_country['report_id'] = (covid_country.groupby(['Province', 'Date']).cumcount()==0).astype(int).cumsum()\n",
    "#         covid_country = covid_country.groupby('report_id', as_index=False).last() # last update within a day #last or first could be ok\n",
    "#         # instead of reindexing as_index argument for groupby is better\n",
    "#         ##covid_country.reset_index(drop=True, inplace=True)\n",
    "#         covid_country.rename(columns={'Confirmed':'AccConfirmed',\n",
    "#                              'Deaths': 'AccDeaths', 'Recovered':'AccRecovered'}, inplace=True)\n",
    "#         covid_country.set_index(['Province', 'Date'], inplace=True)\n",
    "    \n",
    "#         grouped_data = covid_country.groupby(level='Province')\n",
    "#         all_provinces_df = []\n",
    "#         for prov, df in grouped_data:\n",
    "#             df['confirmed'] = df['AccConfirmed'].diff(1)\n",
    "#             df.loc[df.index[0], 'confirmed'] = df.loc[df.index[0], 'AccConfirmed']\n",
    "#             df['deaths'] = df['AccDeaths'].diff(1)\n",
    "#             df.loc[df.index[0], 'deaths'] = df.loc[df.index[0], 'AccDeaths']\n",
    "#             df['recovered'] = df['AccRecovered'].diff(1)\n",
    "#             df.loc[df.index[0], 'recovered'] = df.loc[df.index[0], 'AccRecovered']\n",
    "\n",
    "#             # df.loc[df['confirmed'] < 0, 'new_confirmed'] = np.nan\n",
    "#             # df.loc[df['deaths'] < 0, 'new_deaths'] = np.nan\n",
    "#             # df.loc[df['recovered'] < 0, 'new_recovered'] = np.nan\n",
    "\n",
    "#             all_provinces_df.append(df)\n",
    "        \n",
    "#         all_df = pd.concat(all_provinces_df, sort=True, verify_integrity=True)\n",
    "#         # all_df.dropna(thresh=2, inplace=True, subset=['AccConfirmed', 'AccDeaths',\n",
    "#         #                                         'AccRecovered', 'confirmed', 'deaths', 'recovered'])\n",
    "#         all_df = all_df.reindex(columns = ['AccConfirmed', 'AccDeaths', 'AccRecovered', \n",
    "#                                           'confirmed', 'deaths', 'recovered', 'Latitude', 'Longitude'])\n",
    "\n",
    "#         return all_df\n",
    "# ausy = covid_by_country_with_states()\n",
    "# ausy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # It seems working for all countries except USA as it has more disaggregated data ; tried with Italy, China, Australia\n",
    "# # Australia\n",
    "# ## disaggregated\n",
    "# # aus_covid_disagg = covid_by_country_with_states()\n",
    "# ## by state\n",
    "# # check grouping with NaN as it is dropped\n",
    "# aus_covid_by_state = aus_covid_disagg.groupby(level='Province')['confirmed', 'deaths', 'recovered'].sum()\n",
    "# ## by date\n",
    "# # aus_covid_by_date = aus_covid_disagg.groupby(level='Date')['confirmed', 'deaths', 'recovered'].sum()\n",
    "# # aus_covid_disagg.head(1000)\n",
    "\n",
    "# # {'Australian Capital Territory': 'ACT',\n",
    "# #  'External territories': 'ET',\n",
    "# #  'From Diamond Princess': 'FDP',\n",
    "# #  'Jervis Bay Territory': 'JBT',\n",
    "# #  'New South Wales': 'NSW',\n",
    "# #  'Northern Territory': 'NT',\n",
    "# #  'Queensland': 'QLD',\n",
    "# #  'South Australia': 'SA',\n",
    "# #  'Tasmania': 'TAS',\n",
    "# #  'Victoria': 'VIC',\n",
    "# #  'Western Australia': 'WA',\n",
    "# #  'Australia': 'AUS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final Dataset for all countries shwoing daily cases\n",
    "# xs = covid_final.groupby('Country').sum().astype(int).sort_values(by=['confirmed', 'deaths'], ascending=False)\n",
    "# filt_out = (xs['confirmed']< 1000) #gathering countries with covid < 1000 cases\n",
    "# add_sum = xs.loc[filt_out].sum() # their sum\n",
    "# xs = xs.loc[- filt_out] # removing them\n",
    "# add_sum.name= 'Others' # giving the series a name (index)\n",
    "# xs.append(add_sum)\n",
    "# xs.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # dates (having month of date index)\n",
    "# vic_covid = aus_covid_disagg.loc['Victoria']\n",
    "# vic_covid['Date'] = vic_covid.index\n",
    "# vic_covid['Month'] = vic_covid['Date'].dt.month\n",
    "# aus_covid = aus_covid_disagg.groupby(level='Date')['confirmed', 'deaths', 'recovered'].sum()\n",
    "# vic_covid = vic_covid.reindex(columns = aus_covid.columns)\n",
    "\n",
    "# aus_covid = aus_covid.rename({col: 'nat_' + col for col in aus_covid.columns}, axis=1)\n",
    "# df_vic_aus = pd.merge(vic_covid, aus_covid, how=\"outer\", left_index=True, right_index=True)\n",
    "# df_vic_aus[['confirmed', 'nat_confirmed']].resample('W').sum().plot(kind='bar', figsize=(15,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bad dates (from Mukti)\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# df = pd.read_excel(r'C:\\Users\\khalil\\OneDrive - Deakin University\\shared_folder\\PhD Project\\Programming\\extra\\bad_dates.xlsx')\n",
    "# df[['day', 'month', 'year']] = df['TnC'].str.split('.', expand=True).astype(int)\n",
    "# df['year'] = np.where(df['year'] <21, df['year'] + 2000, df['year'])\n",
    "# df['year'] = np.where(df['year'] <99, df['year'] + 1900, df['year'])\n",
    "# df['year'] = np.where(df['year'] <999, df['year'] + 1000, df['year'])\n",
    "# df['date'] = pd.to_datetime(df[['day', 'month', 'year']].astype(str), dayfirst=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parsing date from components\n",
    "# df = pd.read_csv('temp.csv', parse_dates=[['day', 'month', 'year']], dayfirst=True, usecols= lambda x: x not in ['DD'], index_col=0)\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ec516beff3ca6baf6182e3f7c87d6121698f03b08e9655de8cfadcf89d14a70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
